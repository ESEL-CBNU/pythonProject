import datetime
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import dataretrieval.nwis as nwis
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# ==========================================
# PART 1: MCP Tool Definition (USGS Data)
# ==========================================
class USGS_MCP_Tool:
    """
    MCP(Model Context Protocol) ìŠ¤íƒ€ì¼ë¡œ ì •ì˜ëœ USGS ë°ì´í„° ë„êµ¬ì…ë‹ˆë‹¤.
    ì™¸ë¶€ ì‹œìŠ¤í…œ(AI ëª¨ë¸ ë“±)ì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    @staticmethod
    def get_hydrology_data(site_id: str, days: int = 60):
        """
        USGS ì‚¬ì´íŠ¸ IDë¥¼ ë°›ì•„ ìœ ëŸ‰(00060)ê³¼ ê°•ìš°ëŸ‰(00045) ë°ì´í„°ë¥¼ í•¨ê»˜ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ“¡ [MCP Tool] USGS NWISì— ì—°ê²° ì¤‘... Site: {site_id}, ê¸°ê°„: {days}ì¼")
        
        end_date = datetime.date.today().strftime('%Y-%m-%d')
        start_date = (datetime.date.today() - datetime.timedelta(days=days)).strftime('%Y-%m-%d')
        
        # 00060: Discharge (ìœ ëŸ‰), 00045: Precipitation (ê°•ìš°ëŸ‰)
        parameter_codes = ['00060', '00045']
        
        try:
            # ë‹¤ì¤‘ íŒŒë¼ë¯¸í„° ìš”ì²­
            df, md = nwis.get_iv(sites=site_id, start=start_date, end=end_date, parameterCd=parameter_codes)
            
            if df.empty:
                raise ValueError("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ì»¬ëŸ¼ ì •ë¦¬ ë° ë§¤í•‘
            rename_map = {}
            for col in df.columns:
                if '00060' in col and not col.endswith('_cd'):
                    rename_map[col] = 'flow'
                elif '00045' in col and not col.endswith('_cd'):
                    rename_map[col] = 'precip'
            
            df = df.rename(columns=rename_map)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            cols_to_keep = ['flow']
            if 'precip' in df.columns:
                cols_to_keep.append('precip')
            else:
                print("âš ï¸ í•´ë‹¹ ì‚¬ì´íŠ¸ì— ê°•ìš° ë°ì´í„°(00045)ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ ëŸ‰ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                df['precip'] = 0.0
                cols_to_keep.append('precip')
                
            df = df[cols_to_keep]
            
            # [ìˆ˜ì •] ë°ì´í„° ì •ì œ: ìŒìˆ˜ ê°’ ì²˜ë¦¬ (ë¡œê·¸ ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€)
            df[df < 0] = np.nan
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìœ ëŸ‰: ë³´ê°„, ê°•ìš°: 0ìœ¼ë¡œ ì±„ì›€)
            df['flow'] = df['flow'].interpolate(method='time')
            df['precip'] = df['precip'].fillna(0)
            
            # ë³´ê°„ í›„ì—ë„ ë‚¨ì•„ìˆëŠ” NaN ì œê±° (ë°ì´í„° ì•ìª½ ë“±)
            df = df.dropna()
            
            print(f"âœ… [MCP Tool] ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ: {len(df)} records")
            return df
            
        except Exception as e:
            print(f"âŒ [MCP Tool] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None

# ==========================================
# PART 2: LSTM Model (PyTorch)
# ==========================================
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        # LSTM Layer
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        # Fully Connected Layer
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # x shape: (batch_size, seq_len, input_size)
        out, _ = self.lstm(x)
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ íˆë“  ìŠ¤í…Œì´íŠ¸ ì‚¬ìš©
        out = out[:, -1, :]
        out = self.fc(out)
        return out

class WaterLevelPredictor:
    def __init__(self, data_df, look_back=24, forecast_horizon=3):
        """
        Args:
            data_df: ì‹œê³„ì—´ ë°ì´í„° (flow, precip ì»¬ëŸ¼ í¬í•¨)
            look_back: ê³¼ê±° 24ì‹œê°„ ë°ì´í„°ë¥¼ ë´„
            forecast_horizon: í–¥í›„ 3ì‹œê°„ì„ ì˜ˆì¸¡í•¨
        """
        self.raw_df = data_df
        self.look_back = look_back
        self.forecast_horizon = forecast_horizon
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¶„ë¦¬
        self.flow_scaler = MinMaxScaler(feature_range=(0, 1))
        self.precip_scaler = MinMaxScaler(feature_range=(0, 1))
        
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    def preprocess(self):
        # [ìˆ˜ì •] ë°ì´í„° ì•ˆì •ì„± í™•ë³´
        raw_flow = np.maximum(self.raw_df['flow'].values.reshape(-1, 1), 0)
        raw_precip = np.maximum(self.raw_df['precip'].values.reshape(-1, 1), 0)
        
        # ë¡œê·¸ ë³€í™˜ ì ìš©
        log_flow = np.log1p(raw_flow) 
        log_precip = np.log1p(raw_precip)
        
        # ìŠ¤ì¼€ì¼ë§
        scaled_flow = self.flow_scaler.fit_transform(log_flow)
        scaled_precip = self.precip_scaler.fit_transform(log_precip)
        
        # íŠ¹ì„± ê²°í•©
        combined_data = np.hstack((scaled_flow, scaled_precip))
        
        # NaN ì²´í¬
        if np.isnan(combined_data).any():
            print("âš ï¸ ì „ì²˜ë¦¬ ì¤‘ NaN ë°œìƒ! 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            combined_data = np.nan_to_num(combined_data)
        
        X, y = [], []
        limit = len(combined_data) - self.look_back - self.forecast_horizon + 1
        
        for i in range(limit):
            X.append(combined_data[i : i + self.look_back, :])
            y.append(scaled_flow[i + self.look_back : i + self.look_back + self.forecast_horizon, 0])
            
        X, y = np.array(X), np.array(y)
        
        X_tensor = torch.tensor(X, dtype=torch.float32)
        y_tensor = torch.tensor(y, dtype=torch.float32)
        
        return X_tensor, y_tensor

    def build_model(self, input_size=2, hidden_size=64):
        print(f"ğŸ§  [LSTM] PyTorch ëª¨ë¸ êµ¬ì¶• ì¤‘ (Input: {input_size}, Output: {self.forecast_horizon})...")
        self.model = LSTMModel(input_size, hidden_size, output_size=self.forecast_horizon).to(self.device)
        self.criterion = nn.MSELoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def train(self, X, y, epochs=30, batch_size=32):
        print(f"ğŸ‹ï¸ [LSTM] í•™ìŠµ ì‹œì‘ (Device: {self.device})...")
        
        if torch.isnan(X).any() or torch.isnan(y).any():
            raise ValueError("í•™ìŠµ ë°ì´í„°ì— NaNì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        dataset = TensorDataset(X, y)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        self.model.train()
        for epoch in range(epochs):
            epoch_loss = 0
            for batch_X, batch_y in dataloader:
                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                
                outputs = self.model(batch_X)
                loss = self.criterion(outputs, batch_y)
                
                self.optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.optimizer.step()
                
                epoch_loss += loss.item()
            
            if (epoch+1) % 5 == 0:
                print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader):.5f}')

    def predict_future(self):
        self.model.eval()
        with torch.no_grad():
            last_flow = self.raw_df['flow'].values[-self.look_back:].reshape(-1, 1)
            last_precip = self.raw_df['precip'].values[-self.look_back:].reshape(-1, 1)
            
            # ìŒìˆ˜ ë°©ì§€ ë° ë¡œê·¸ ë³€í™˜
            last_flow = np.maximum(last_flow, 0)
            last_precip = np.maximum(last_precip, 0)
            
            log_last_flow = np.log1p(last_flow)
            log_last_precip = np.log1p(last_precip)
            
            scaled_flow = self.flow_scaler.transform(log_last_flow)
            scaled_precip = self.precip_scaler.transform(log_last_precip)
            
            last_combined = np.hstack((scaled_flow, scaled_precip))
            
            X_input = torch.tensor(last_combined, dtype=torch.float32).unsqueeze(0).to(self.device)
            
            predicted_scaled = self.model(X_input).cpu().numpy()
            
            predicted_log = self.flow_scaler.inverse_transform(predicted_scaled)
            predicted_values = np.expm1(predicted_log)
            
            predicted_values = np.maximum(predicted_values, 0.0)
        
        return predicted_values[0]

# ==========================================
# PART 3: Main Execution Flow
# ==========================================
if __name__ == "__main__":
    # Potomac River near Washington, DC
    TARGET_SITE = '01646500' 
    
    print("--- 1. Data Collection via MCP (Flow & Precip) ---")
    df = USGS_MCP_Tool.get_hydrology_data(TARGET_SITE, days=60)
    
    if df is not None:
        print("âš™ï¸ [Processing] 1ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ë¦¬ìƒ˜í”Œë§ ì¤‘...")
        df_resampled = df.resample('1h').agg({'flow': 'mean', 'precip': 'sum'})
        
        df_resampled['flow'] = df_resampled['flow'].interpolate(method='time')
        df_resampled['precip'] = df_resampled['precip'].fillna(0)
        df_resampled = df_resampled.dropna()
        
        # ë¦¬ìƒ˜í”Œë§ í›„ì—ë„ ìŒìˆ˜ê°€ ìƒê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ(ë³´ê°„ë²• ë“±) 0ìœ¼ë¡œ í´ë¦¬í•‘
        df_resampled[df_resampled < 0] = 0
        
        print(f"âœ… ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: {len(df_resampled)} records")

        print("\n--- 2. Data Preprocessing ---")
        predictor = WaterLevelPredictor(df_resampled, look_back=24, forecast_horizon=3)
        X, y = predictor.preprocess()
        
        train_size = int(len(X) * 0.8)
        X_train, y_train = X[:train_size], y[:train_size]
        
        print("\n--- 3. Model Training ---")
        predictor.build_model(input_size=2)
        predictor.train(X_train, y_train, epochs=50)
        
        print("\n--- 4. Future Prediction (Next 3 Hours) ---")
        future_vals = predictor.predict_future()
        current_val = df_resampled['flow'].iloc[-1]
        
        print(f"\nğŸŒŠ [Result]")
        print(f"í˜„ì¬ ìœ ëŸ‰: {current_val:.2f} ftÂ³/s")
        for i, val in enumerate(future_vals):
            print(f"â¡ï¸ {i+1}ì‹œê°„ í›„ ì˜ˆì¸¡: {val:.2f} ftÂ³/s")
        
        print("\n--- 5. Visualization (Interactive) ---")
        # [ìˆ˜ì •] ì¸í„°ë™í‹°ë¸Œ ê·¸ë˜í”„ë¥¼ ìœ„í•´ subplots ì‚¬ìš©
        fig, ax = plt.subplots(figsize=(12, 6))
        
        display_days = 7
        display_data = df_resampled.iloc[-(display_days*24):]
        
        # ìœ ëŸ‰ ë°ì´í„° í”Œë¡¯ (ë³€ìˆ˜ì— í• ë‹¹í•˜ì—¬ ì´ë²¤íŠ¸ í•¸ë“¤ë§ì— ì‚¬ìš©)
        line_obs, = ax.plot(display_data.index, display_data['flow'], label='Observed Flow', color='blue')
        
        # ê°•ìš° ë°ì´í„° (ë³´ì¡°ì¶•)
        if display_data['precip'].sum() > 0:
            ax2 = ax.twinx()
            ax2.bar(display_data.index, display_data['precip'], color='gray', alpha=0.3, label='Precipitation', width=0.04)
            ax2.set_ylabel('Precipitation', color='gray')
        
        last_time = display_data.index[-1]
        future_times = [last_time + datetime.timedelta(hours=i+1) for i in range(3)]
        
        ax.plot(future_times, future_vals, 'r--', label='Predicted Flow')
        # ì˜ˆì¸¡ í¬ì¸íŠ¸ (ë³€ìˆ˜ì— í• ë‹¹)
        scat_pred = ax.scatter(future_times, future_vals, color='red', s=100, zorder=5)
        
        for i, (t, v) in enumerate(zip(future_times, future_vals)):
            ax.text(t, v, f'{i+1}h', fontsize=10, verticalalignment='bottom', fontweight='bold', color='darkred')

        ax.set_title(f"USGS Flow Forecast w/ Rainfall (Site: {TARGET_SITE})")
        ax.set_xlabel("Date")
        ax.set_ylabel("Discharge (ftÂ³/s)")
        ax.legend(loc='upper left')
        ax.grid(True)
        
        # ==========================================
        # [ê¸°ì¡´] Hover Tooltip (ì»¤ì„œ ì˜¬ë¦¬ë©´ ê°’ í‘œì‹œ)
        # ==========================================
        annot = ax.annotate("", xy=(0,0), xytext=(15,15), textcoords="offset points",
                            bbox=dict(boxstyle="round", fc="w", alpha=0.8),
                            arrowprops=dict(arrowstyle="->"))
        annot.set_visible(False)

        def update_annot(ind, artist):
            if isinstance(artist, plt.Line2D):
                x, y = artist.get_data()
                idx = ind["ind"][0]
                annot.xy = (x[idx], y[idx])
                text = f"{y[idx]:.2f} ftÂ³/s"
            elif isinstance(artist, type(scat_pred)):
                offsets = artist.get_offsets()
                idx = ind["ind"][0]
                annot.xy = (offsets[idx][0], offsets[idx][1])
                text = f"{offsets[idx][1]:.2f} ftÂ³/s"
            annot.set_text(text)

        def hover(event):
            vis = annot.get_visible()
            if event.inaxes == ax:
                cont_scat, ind_scat = scat_pred.contains(event)
                if cont_scat:
                    update_annot(ind_scat, scat_pred)
                    annot.set_visible(True)
                    fig.canvas.draw_idle()
                    return

                cont_line, ind_line = line_obs.contains(event)
                if cont_line:
                    update_annot(ind_line, line_obs)
                    annot.set_visible(True)
                    fig.canvas.draw_idle()
                    return

            if vis:
                annot.set_visible(False)
                fig.canvas.draw_idle()

        fig.canvas.mpl_connect("motion_notify_event", hover)

        # ==========================================
        # [ì¶”ê°€] Zoom Functionality (Mouse Wheel)
        # ==========================================
        def zoom(event):
            base_scale = 1.2 # í™•ëŒ€/ì¶•ì†Œ ë¹„ìœ¨
            # í˜„ì¬ xì¶• ë²”ìœ„ ê°€ì ¸ì˜¤ê¸°
            cur_xlim = ax.get_xlim()
            cur_xrange = (cur_xlim[1] - cur_xlim[0])
            xdata = event.xdata # ë§ˆìš°ìŠ¤ í¬ì¸í„°ì˜ x ì¢Œí‘œ
            
            if event.button == 'up':
                # íœ  ì˜¬ë¦¬ê¸°: í™•ëŒ€ (Zoom In)
                scale_factor = 1 / base_scale
            elif event.button == 'down':
                # íœ  ë‚´ë¦¬ê¸°: ì¶•ì†Œ (Zoom Out)
                scale_factor = base_scale
            else:
                scale_factor = 1
                
            if xdata is None: # ë§ˆìš°ìŠ¤ê°€ ê·¸ë˜í”„ ì˜ì—­ ë°–ì— ìˆìœ¼ë©´ ë¬´ì‹œ
                return

            # ìƒˆë¡œìš´ xì¶• ë²”ìœ„ ê³„ì‚° (ë§ˆìš°ìŠ¤ ìœ„ì¹˜ ì¤‘ì‹¬)
            new_width = cur_xrange * scale_factor
            relx = (cur_xlim[1] - xdata) / (cur_xlim[1] - cur_xlim[0])
            
            ax.set_xlim([xdata - new_width * (1 - relx), xdata + new_width * (relx)])
            fig.canvas.draw_idle() # ê·¸ë˜í”„ ê°±ì‹ 

        fig.canvas.mpl_connect('scroll_event', zoom)
        
        print("ğŸ’¡ íŒ: ê·¸ë˜í”„ ìœ„ì—ì„œ ë§ˆìš°ìŠ¤ íœ ì„ êµ´ë ¤ í™•ëŒ€/ì¶•ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        # ==========================================
        
        plt.savefig('prediction_graph_improved.png')
        print("ğŸ“Š ê·¸ë˜í”„ê°€ 'prediction_graph_improved.png' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        plt.show()

    else:
        print("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")